Abstract:
	Neural Networks have been around for a suprisiungly long time. Back in 1943 Warren McColloch[1] attempted to describe how a neuron would work in the brain by modeling a neural network using electrical circuts. Today neural networks are the heart of all machine learning news. Work with neural networks is revered to the highest degree given their complexity and ability to be accurate given a large amount of data. In this experiment we venture into the world of neural networks and implement a feedforward neural network using the algorithm backpropagation. In the next couple sections I describe the problem and hypothesize what the outcome of this experiment will be. Later, I will describe the algorithm that was implemented and summarize my results. We will conclude with closing thoughts about the behavior of the algorithm and summary of the experiement.

	Backpropogation:
		In this experiment we used backpropogation in our neural network. We use backpropogation to calculate the gradient of the weights that we use in the network at each of the neuons. We first initialize the network with the first